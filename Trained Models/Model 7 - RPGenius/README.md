# RPG Level Generator â€” LoRA Fineâ€‘Tuned Model (60,000â€‘row dataset)


**Base model:** TinyLLaMAâ€‘1.1B (causal LM)  
**Goal:** Generate highâ€‘quality, progressively challenging RPG maps as compact JSON/ASCII grids.  
**This is our best finetune so far**, trained on **60,000** curated level records, with a **GPTâ€‘4oâ€‘mini fallback** for lateâ€‘game depth.

---

## ğŸ”— Quick Links (replace with your Hugging Face URLs)

- **Model:** [Hugging Face model page](<https://huggingface.co/Hirudika2002/JARVIS-Models/tree/main/LoRA-Trained/Model-7-Advanced(60%2C000_Rows)>)
- **Demo Video:** [Hugging Face Spaces / video](<https://huggingface.co/Hirudika2002/JARVIS-Models/blob/main/Model_Demo_Videos/Model_7(60000_DataLines)Demo_video.mp4>)
- **Dataset (used for training):** [Hugging Face dataset](<https://huggingface.co/Hirudika2002/JARVIS-Models/tree/main/DataSets/For%2060%2C000%20Rows>)

> Keep these at the top so users can jump directly to the model, demo, and data.

---

## TL;DR

- **60kâ€‘row** finetune on TinyLLaMAâ€‘1.1B producing **complex, detailed** maps with **strong variety** and **stable progression**.  
- Consistently strong from **L1 â†’ L8**; **often reaches L9â€“L10** before fallback.  
- **Quality is noticeably higher**: authentic feel, better pathways, advanced layouts.  
- Occasional **validatorâ€‘triggered retries**, but final outputs remain **stable and playable**.  
- Best balance so far between **stability, complexity, and quality**.

---

## ğŸ¯ Performance Summary

| Capability | What you can expect |
|---|---|
| Level coverage | Consistent L1â€“L8; often L9â€“L10; fallback beyond 9â€“10 |
| Structure quality | High â€” advanced layouts, strong flow, improved pathways |
| Stability | High across multiâ€‘level sequences; occasional retries due to strict validators |
| Diversity | Strong â€” reduced repetition vs. all earlier models |
| Progression | Smooth and engaging; difficulty scaling feels natural |

---

## ğŸ” Observations

- The **60k dataset** captures **richer design patterns** and **reduces repetition**.  
- **Complexity and creativity** are **significantly better** than previous runs (10kâ€“40k).  
- **Retries** during generation can occur because of **tighter validators**, which is expected when targeting complex maps.  
- Overall, this model achieves the **most balanced tradeâ€‘off** among **stability, complexity, and quality** to date.

---

## âš ï¸ Limitations

- Still **falls back around L9â€“L10**; not sustaining very deep progression **natively**.  
- **Retry loops** may increase slightly for **very complex** layouts.  
- Even at 60k, the dataset may **not fully cover lateâ€‘game** structural diversity.

---


**Policy:** Use the **local TinyLLaMAâ€‘1.1B finetune for L1â€“L8** (frequently L9â€“L10). Fall back **beyond L9â€“L10** or when **validation fails/exceeds retries**.


---

## ğŸ§± Output Format & Invariants

```json
{
  "level": {"name": "9", "level_index": 9, "difficulty": 5, "time": 300, "width": 15, "height": 10},
  "walls": [{"start_pos": {"x": 0, "y": 0}, "end_pos": {"x": 14, "y": 0}}],
  "small_obstacles": [{"x": 6, "y": 3}, {"x": 8, "y": 6}],
  "enemies": [{"x": 4, "y": 5}, {"x": 10, "y": 7}],
  "player_pos": {"x": 1, "y": 1}
}


